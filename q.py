import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
import re
import os
from datetime import datetime, timezone, timedelta
import time
import random
import sys
import hashlib
import json
import base64
from urllib.parse import urlparse, urljoin
import sqlite3
from unidecode import unidecode

# AI ê´€ë ¨ import
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

def get_env_var(name, default=None):
    """í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°"""
    return os.environ.get(name, default)


def init_processed_db():
    """ì²˜ë¦¬ëœ ê¸°ì‚¬ ì¶”ì ì„ ìœ„í•œ SQLite DB ì´ˆê¸°í™”"""
    db_path = 'processed_articles.db'
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS processed_articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            url TEXT UNIQUE,
            title TEXT,
            hash TEXT,
            processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()
    return db_path

def is_article_processed(url, title, article_hash):
    """ê¸°ì‚¬ê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ DBì—ì„œ í™•ì¸ (ê°•í™”ëœ URL ì²´í¬)"""
    db_path = 'processed_articles.db'
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # 1. URL ì§ì ‘ ì²´í¬ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
    cursor.execute('SELECT COUNT(*) FROM processed_articles WHERE url = ?', (url,))
    url_count = cursor.fetchone()[0]
    
    if url_count > 0:
        conn.close()
        return True
    
    # 2. í•´ì‹œ ê¸°ë°˜ ì²´í¬ (ì œëª©+URL ì¡°í•©)
    cursor.execute('SELECT COUNT(*) FROM processed_articles WHERE hash = ?', (article_hash,))
    hash_count = cursor.fetchone()[0]
    
    conn.close()
    return hash_count > 0

def mark_article_processed(url, title, article_hash):
    """ê¸°ì‚¬ë¥¼ ì²˜ë¦¬ë¨ìœ¼ë¡œ DBì— ê¸°ë¡"""
    db_path = 'processed_articles.db'
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            INSERT OR REPLACE INTO processed_articles (url, title, hash)
            VALUES (?, ?, ?)
        ''', (url, title, article_hash))
        
        conn.commit()
    except Exception as e:
        print(f"âš ï¸ Failed to mark article as processed: {e}")
    finally:
        conn.close()

def clean_filename(title):
    """ì œëª©ì„ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬"""
    filename = re.sub(r'[^\w\s-]', '', title)
    filename = re.sub(r'[-\s]+', '-', filename)
    return filename.strip('-').lower()

def create_url_slug(title):
    """ì œëª©ì„ URL ìŠ¬ëŸ¬ê·¸ë¡œ ë³€í™˜ (ì˜ë¬¸, 3~4ë‹¨ì–´ë¡œ ì œí•œ)"""
    try:
        # í•œê¸€ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜ (unidecode ì‚¬ìš©)
        slug = unidecode(title)
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê³µë°±ì„ í•˜ì´í”ˆìœ¼ë¡œ
        slug = re.sub(r'[^\w\s-]', '', slug)
        slug = re.sub(r'[-\s]+', '-', slug)
        # ì†Œë¬¸ìë¡œ ë³€í™˜, ì•ë’¤ í•˜ì´í”ˆ ì œê±°
        slug = slug.strip('-').lower()
        
        # 3~4ë‹¨ì–´ë¡œ ì œí•œ (í•˜ì´í”ˆìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ ê¸°ì¤€)
        words = slug.split('-')
        if len(words) > 4:
            # ì²« 4ê°œ ë‹¨ì–´ë§Œ ì‚¬ìš©
            slug = '-'.join(words[:4])
        elif len(words) < 3 and len(words) > 0:
            # 2ë‹¨ì–´ ì´í•˜ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ìœ ì§€ (ë„ˆë¬´ ì§§ì§€ ì•Šë„ë¡)
            pass
        
        # ìµœëŒ€ ê¸¸ì´ ì œí•œ (ì•ˆì „ì¥ì¹˜)
        if len(slug) > 50:
            slug = slug[:50].rstrip('-')
            
        return slug
    except:
        # unidecode ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©
        return clean_filename(title)

def categorize_article(title, content, tags):
    """ê¸°ì‚¬ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    title_lower = title.lower()
    content_lower = content.lower()
    all_tags = [tag.lower() for tag in tags]
    
    # ìë™ì°¨ ê´€ë ¨ í‚¤ì›Œë“œ
    car_keywords = [
        'car', 'auto', 'vehicle', 'ìë™ì°¨', 'ì°¨ëŸ‰', 'ìŠ¹ìš©ì°¨', 'íŠ¸ëŸ­', 'ë²„ìŠ¤',
        'í˜„ëŒ€', 'ê¸°ì•„', 'ì‚¼ì„±', 'í…ŒìŠ¬ë¼', 'tesla', 'hyundai', 'kia',
        'ì „ê¸°ì°¨', 'ev', 'electric', 'ìˆ˜ì†Œì°¨', 'hydrogen',
        'ì—”ì§„', 'ëª¨í„°', 'ë°°í„°ë¦¬', 'ì¶©ì „', 'ì£¼í–‰', 'ìš´ì „',
        'í´ë“œ', 'fold', 'ê°¤ëŸ­ì‹œ', 'galaxy', 'ìŠ¤ë§ˆíŠ¸í°', 'smartphone'
    ]
    
    # ê²½ì œ ê´€ë ¨ í‚¤ì›Œë“œ  
    economy_keywords = [
        'economy', 'economic', 'ê²½ì œ', 'ê¸ˆìœµ', 'íˆ¬ì', 'ì£¼ì‹', 'ì½”ìŠ¤í”¼', 'ì¦ì‹œ',
        'ë‹¬ëŸ¬', 'ì›í™”', 'í™˜ìœ¨', 'ê¸ˆë¦¬', 'ì¸í”Œë ˆì´ì…˜', 'ë¬¼ê°€',
        'ê¸°ì—…', 'íšŒì‚¬', 'ë§¤ì¶œ', 'ì´ìµ', 'ì†ì‹¤', 'ì‹¤ì ',
        'ì •ì±…', 'ì •ë¶€', 'ì€í–‰', 'ì¤‘ì•™ì€í–‰'
    ]
    
    # ê¸°ìˆ /IT ê´€ë ¨ í‚¤ì›Œë“œ
    tech_keywords = [
        'tech', 'technology', 'it', 'ê¸°ìˆ ', 'ì†Œí”„íŠ¸ì›¨ì–´', 'í•˜ë“œì›¨ì–´',
        'ai', 'ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 
        'ì•±', 'app', 'í”Œë«í¼', 'platform', 'ì„œë¹„ìŠ¤',
        'êµ¬ê¸€', 'google', 'ì• í”Œ', 'apple', 'ë§ˆì´í¬ë¡œì†Œí”„íŠ¸', 'microsoft'
    ]
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    car_score = sum(1 for keyword in car_keywords if keyword in title_lower or keyword in content_lower or keyword in all_tags)
    economy_score = sum(1 for keyword in economy_keywords if keyword in title_lower or keyword in content_lower or keyword in all_tags)
    
    # automotive ë˜ëŠ” economy ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©
    if car_score >= economy_score:
        return 'automotive'
    else:
        return 'economy'

def get_article_hash(title, url):
    """ê¸°ì‚¬ì˜ ê³ ìœ  í•´ì‹œ ìƒì„± (ì¤‘ë³µ ë°©ì§€ìš©)"""
    content = f"{title}{url}"
    return hashlib.md5(content.encode()).hexdigest()[:8]

def check_existing_articles(output_dir, article_hash, title, url):
    """ê°•í™”ëœ ê¸°ì‚¬ ì¤‘ë³µ ì²´í¬ (ì„œë¸Œë””ë ‰í† ë¦¬ í¬í•¨) - URL ìš°ì„ """
    if not os.path.exists(output_dir):
        return False
    
    # ì œëª© ê¸°ë°˜ ìœ ì‚¬ë„ ì²´í¬ë¥¼ ìœ„í•œ ì •ê·œí™”
    normalized_title = re.sub(r'[^\w\s]', '', title.lower()).strip()
    
    # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì™€ ëª¨ë“  ì„œë¸Œë””ë ‰í† ë¦¬ ê²€ì‚¬
    for root, dirs, files in os.walk(output_dir):
        for filename in files:
            if filename.endswith('.md'):
                filepath = os.path.join(root, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        # 1. URL ê¸°ë°˜ ì²´í¬ (ìµœìš°ì„  - ê°€ì¥ í™•ì‹¤)
                        if f'source_url: "{url}"' in content:
                            return True
                        
                        # 2. í•´ì‹œ ê¸°ë°˜ ì²´í¬
                        if f"hash: {article_hash}" in content:
                            return True
                        
                        # 3. ì œëª© ìœ ì‚¬ë„ ì²´í¬ (ë³´ì™„ì )
                        title_match = re.search(r'title: "([^"]+)"', content)
                        if title_match:
                            existing_title = title_match.group(1)
                            existing_normalized = re.sub(r'[^\w\s]', '', existing_title.lower()).strip()
                            
                            # ì œëª©ì´ 95% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨
                            if normalized_title and existing_normalized:
                                title_words = set(normalized_title.split())
                                existing_words = set(existing_normalized.split())
                                if title_words and existing_words:
                                    similarity = len(title_words & existing_words) / len(title_words | existing_words)
                                    if similarity > 0.95:
                                        return True
                                
                except Exception:
                    continue
    return False

def create_manual_rewrite(original_content, title):
    """AI ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ìœ¼ë¡œ ê¸°ì‚¬ ì¬ì‘ì„± - ê·¹ë‹¨ì  ë³€í˜•"""
    try:
        # ì›ë³¸ ì½˜í…ì¸ ë¥¼ ë¬¸ë‹¨ë³„ë¡œ ë¶„ë¦¬
        paragraphs = original_content.split('\n\n')
        rewritten_paragraphs = []
        
        # ë¬¸ì²´ ë³€í˜•ì„ ìœ„í•œ í‘œí˜„ ì‚¬ì „
        style_transforms = {
            "ë°œí‘œí–ˆë‹¤": ["ê³µê°œí–ˆë‹¤", "ë°í˜”ë‹¤", "ì•Œë ¸ë‹¤", "ì „í–ˆë‹¤", "ê³µí‘œí–ˆë‹¤"],
            "ì¦ê°€í–ˆë‹¤": ["ëŠ˜ì–´ë‚¬ë‹¤", "ìƒìŠ¹í–ˆë‹¤", "í™•ëŒ€ëë‹¤", "ì„±ì¥í–ˆë‹¤", "ì˜¤ë¦„ì„¸ë¥¼ ë³´ì˜€ë‹¤"],
            "ê°ì†Œí–ˆë‹¤": ["ì¤„ì–´ë“¤ì—ˆë‹¤", "í•˜ë½í–ˆë‹¤", "ì¶•ì†Œëë‹¤", "ë‚´ë¦¼ì„¸ë¥¼ ë³´ì˜€ë‹¤", "ë‘”í™”ëë‹¤"],
            "ê³„íšì´ë‹¤": ["ì˜ˆì •ì´ë‹¤", "ë°©ì¹¨ì´ë‹¤", "êµ¬ìƒì´ë‹¤", "ì˜ë„ë‹¤", "ê³„íšì„ ì„¸ì› ë‹¤"],
            "ë¬¸ì œê°€": ["ì´ìŠˆê°€", "ìš°ë ¤ê°€", "ìŸì ì´", "ê³¼ì œê°€", "ë‚œì œê°€"],
            "ì¤‘ìš”í•˜ë‹¤": ["í•µì‹¬ì ì´ë‹¤", "ì£¼ìš”í•˜ë‹¤", "ê²°ì •ì ì´ë‹¤", "í•„ìˆ˜ì ì´ë‹¤", "ê´€ê±´ì´ë‹¤"],
            "ì§„í–‰ëë‹¤": ["ì´ë¤„ì¡Œë‹¤", "ì¶”ì§„ëë‹¤", "ì‹¤ì‹œëë‹¤", "ê°œìµœëë‹¤", "í¼ì³ì¡Œë‹¤"]
        }
        
        # ì ‘ì†ì‚¬ ë° ì‹œì‘ í‘œí˜„ ë‹¤ì–‘í™”
        connectors = [
            "í•œí¸", "ë˜í•œ", "ì´ì™€ ê´€ë ¨í•´", "íŠ¹íˆ", "ë”ë¶ˆì–´", "ì•„ìš¸ëŸ¬", 
            "ê·¸ëŸ° ê°€ìš´ë°", "ì´ëŸ° ìƒí™©ì—ì„œ", "ì£¼ëª©í•  ì ì€", "ëˆˆì—¬ê²¨ë³¼ ëŒ€ëª©ì€",
            "ì—…ê³„ì— ë”°ë¥´ë©´", "ì „ë¬¸ê°€ë“¤ì€", "ê´€ê³„ìë“¤ì— ì˜í•˜ë©´"
        ]
        
        # ê° ë¬¸ë‹¨ì„ ê·¹ë‹¨ì ìœ¼ë¡œ ì¬êµ¬ì„±
        for i, paragraph in enumerate(paragraphs):
            if not paragraph.strip():
                continue
                
            sentences = paragraph.split('.')
            if len(sentences) > 1:
                rewritten_sentences = []
                
                for j, sentence in enumerate(sentences):
                    sentence = sentence.strip()
                    if not sentence:
                        continue
                    
                    # 1. í‘œí˜„ ì‚¬ì „ì„ í™œìš©í•œ ì–´íœ˜ ë³€ê²½
                    for original, alternatives in style_transforms.items():
                        if original in sentence:
                            import random
                            sentence = sentence.replace(original, random.choice(alternatives))
                    
                    # 2. ë¬¸ì¥ êµ¬ì¡° ë³€í˜•
                    if "ëŠ”" in sentence and "ì´ë‹¤" in sentence:
                        # "AëŠ” Bì´ë‹¤" â†’ "Bë¡œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì´ Aë‹¤"
                        parts = sentence.split("ëŠ”")
                        if len(parts) == 2:
                            subject = parts[0].strip()
                            predicate = parts[1].strip()
                            if "ì´ë‹¤" in predicate:
                                predicate = predicate.replace("ì´ë‹¤", "ë¡œ í™•ì¸ë˜ëŠ” ê²ƒì´")
                                sentence = f"{predicate} {subject}ë‹¤"
                    
                    # 3. ìˆ«ì í‘œí˜„ ë³€í˜•
                    import re
                    percent_pattern = r'(\d+)%'
                    sentence = re.sub(percent_pattern, lambda m: f"100ëª… ì¤‘ {m.group(1)}ëª…", sentence)
                    
                    # 4. ë¬¸ì¥ ì‹œì‘ ë‹¤ì–‘í™”
                    if j == 0 and i > 0:
                        connector = connectors[i % len(connectors)]
                        if not any(sentence.startswith(conn) for conn in connectors):
                            sentence = f"{connector} {sentence.lower()}"
                    
                    # 5. ì§ˆë¬¸í˜•/ê°íƒ„í˜• ë³€í˜• (ì¼ë¶€ ë¬¸ì¥ì„)
                    if j % 3 == 0 and "ì¤‘ìš”" in sentence:
                        sentence = sentence.replace("ì¤‘ìš”í•˜ë‹¤", "ì¤‘ìš”í•˜ì§€ ì•Šì„ê¹Œ?")
                    elif "ë†€ë¼ìš´" in sentence or "ì£¼ëª©" in sentence:
                        sentence = sentence + "!"
                    
                    rewritten_sentences.append(sentence)
                
                if rewritten_sentences:
                    # ë¬¸ì¥ ìˆœì„œë„ ì¼ë¶€ ë³€ê²½
                    if len(rewritten_sentences) > 2:
                        # ë§ˆì§€ë§‰ ë¬¸ì¥ì„ ì•ìœ¼ë¡œ ì´ë™ (ë•Œë•Œë¡œ)
                        if i % 2 == 0:
                            last_sentence = rewritten_sentences.pop()
                            rewritten_sentences.insert(0, last_sentence)
                    
                    rewritten_paragraphs.append('. '.join(rewritten_sentences) + '.')
            else:
                # ë‹¨ì¼ ë¬¸ì¥ë„ ë³€í˜•
                paragraph = paragraph.strip()
                for original, alternatives in style_transforms.items():
                    if original in paragraph:
                        import random
                        paragraph = paragraph.replace(original, random.choice(alternatives))
                rewritten_paragraphs.append(paragraph)
        
        # 35~60ëŒ€ ë…ìì¸µì„ ìœ„í•œ ê¸°ë³¸ êµ¬ì¡°ë¡œ ì¬êµ¬ì„± (H5 í•˜ë‚˜ì— <br> ë‘ ì¤„ + ì¸ë„¤ì¼ + ë³¸ë¬¸ + H2 ì†Œì œëª©)
        rewritten_content = f"""##### **{title}ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½**<br>**ì—…ê³„ ë™í–¥ê³¼ í–¥í›„ ì „ë§ ë¶„ì„**

{chr(10).join(rewritten_paragraphs[:3])}

## í•µì‹¬ í¬ì¸íŠ¸

{chr(10).join(rewritten_paragraphs[3:6]) if len(rewritten_paragraphs) > 3 else ''}

## ìƒì„¸ ë¶„ì„

{chr(10).join(rewritten_paragraphs[6:]) if len(rewritten_paragraphs) > 6 else ''}

**ì´ë²ˆ ì´ìŠˆëŠ” ì—…ê³„ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•˜ê³  ìˆìœ¼ë©°**, í–¥í›„ ë™í–¥ì— ëŒ€í•œ ì§€ì†ì ì¸ ê´€ì‹¬ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤.
"""
        
        return rewritten_content.strip()
        
    except Exception as e:
        print(f"âš ï¸ Manual rewrite failed: {e}")
        # ìµœì†Œí•œì˜ ê¸°ë³¸ êµ¬ì¡°ë¼ë„ ìƒì„± (H5 í•˜ë‚˜ì— <br> ë‘ ì¤„ + H2 ì†Œì œëª©)
        return f"""##### **ì—…ê³„ ì£¼ìš” ë™í–¥ í•µì‹¬ ë¶„ì„**<br>**{title} ì˜í–¥ê³¼ ì‹œì¥ ì „ë§**

ë³¸ ê¸°ì‚¬ëŠ” í˜„ì¬ ì—…ê³„ì˜ ì£¼ìš” ë™í–¥ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.

## í•µì‹¬ í¬ì¸íŠ¸

ê´€ë ¨ ì—…ê³„ì—ì„œëŠ” ì´ë²ˆ ì‚¬ì•ˆì— ëŒ€í•´ **ë†’ì€ ê´€ì‹¬ì„ ë³´ì´ê³  ìˆìœ¼ë©°**, ë‹¤ì–‘í•œ ì˜ê²¬ì´ ì œê¸°ë˜ê³  ìˆëŠ” ìƒí™©ì…ë‹ˆë‹¤.

## í–¥í›„ ì „ë§

ì´ëŸ¬í•œ ë³€í™”ëŠ” ì‹œì¥ì— ì¤‘ëŒ€í•œ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, **ê´€ë ¨ ê¸°ì—…ë“¤ì˜ ëŒ€ì‘ ì „ëµì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤**.

*ë³¸ ê¸°ì‚¬ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""

def upload_to_cloudflare_images(image_url, api_token, account_id):
    """Cloudflare Imagesì— ì´ë¯¸ì§€ ì—…ë¡œë“œ"""
    try:
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        img_response = requests.get(image_url, headers=headers, timeout=10)
        img_response.raise_for_status()
        
        # Cloudflare Images API í˜¸ì¶œ
        upload_url = f"https://api.cloudflare.com/client/v4/accounts/{account_id}/images/v1"
        
        files = {
            'file': ('image.jpg', img_response.content, 'image/jpeg')
        }
        headers = {
            'Authorization': f'Bearer {api_token}'
        }
        
        response = requests.post(upload_url, files=files, headers=headers)
        response.raise_for_status()
        
        result = response.json()
        if result.get('success'):
            # Cloudflare Images URL ë°˜í™˜ (í•˜ë“œì½”ë”©ëœ account hash ì‚¬ìš©)
            image_id = result['result']['id']
            account_hash = "BhPWbivJAhTvor9c-8lV2w"  # í•˜ë“œì½”ë”©ëœ account hash
            cloudflare_url = f"https://imagedelivery.net/{account_hash}/{image_id}/public"
            print(f"ğŸ“¸ Cloudflare image URL: {cloudflare_url}")
            return cloudflare_url
        else:
            print(f"âŒ Cloudflare upload failed: {result}")
            return None  # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
            
    except Exception as e:
        print(f"âš ï¸ Failed to upload image to Cloudflare: {e}")
        return None  # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

def rewrite_with_ai(original_content, title, api_key, api_type="openai"):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ ì¬ì‘ì„±"""
    if not api_key:
        raise Exception("No AI API key provided - AI rewrite is mandatory")
    
    # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
    for attempt in range(3):
        try:
            print(f"ğŸ¤– AI rewrite attempt {attempt + 1}/3...")
            if api_type == "openai" and HAS_OPENAI:
                client = OpenAI(api_key=api_key)
                
                prompt = f"""
ë‹¤ìŒ ì›ë³¸ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ **ì™„ì „íˆ ìƒˆë¡œìš´ ê´€ì ê³¼ ë¬¸ì²´**ë¡œ ì¬ì°½ì‘í•´ì£¼ì„¸ìš”.
ì›ë³¸ ì‘ì„±ìê°€ ìì‹ ì˜ ê¸€ì´ë¼ê³  ì¸ì‹í•  ìˆ˜ ì—†ì„ ì •ë„ë¡œ **í˜ì‹ ì ìœ¼ë¡œ ë³€í˜•**í•´ì£¼ì„¸ìš”.

ì œëª©: {title}

ì›ë³¸ ê¸°ì‚¬:
{original_content}

**ê·¹ë‹¨ì  ë³€í˜• ìš”êµ¬ì‚¬í•­:**
1. **ë¬¸ì²´ ì™„ì „ ë³€ê²½**: ì›ë³¸ì´ ë”±ë”±í•˜ë©´ ì¹œê·¼í•˜ê²Œ, ì¹œê·¼í•˜ë©´ ì „ë¬¸ì ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”
2. **ì‹œì‘ ê°ë„ í˜ì‹ **: ì›ë³¸ê³¼ ì „í˜€ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì‚¬ê±´ì„ ì ‘ê·¼í•´ì£¼ì„¸ìš”
3. **ë¬¸ì¥ êµ¬ì¡° íŒŒê´´**: ì›ë³¸ì˜ ë¬¸ì¥ íŒ¨í„´ì„ ì™„ì „íˆ í•´ì²´í•˜ê³  ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”
4. **ì–´íœ˜ ì„ íƒ ë³€í™”**: ê°™ì€ ì˜ë¯¸ì˜ ë‹¤ë¥¸ í‘œí˜„, ë‹¤ë¥¸ ë‰˜ì•™ìŠ¤ë¡œ ë°”ê¿”ì£¼ì„¸ìš”
5. **ë…¼ë¦¬ íë¦„ ì¬ë°°ì¹˜**: ì •ë³´ ì œì‹œ ìˆœì„œë¥¼ ì™„ì „íˆ ì¬ë°°ì—´í•´ì£¼ì„¸ìš”
6. **ìŠ¤íƒ€ì¼ ì •ì²´ì„± ë³€ê²½**: ë§ˆì¹˜ ì„±ê²©ì´ ë‹¤ë¥¸ ê¸°ìê°€ ì“´ ê²ƒì²˜ëŸ¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”
7. **í‘œí˜„ ê¸°ë²• ë‹¤ë³€í™”**: 
   - ì§ˆë¬¸í˜•/ì„œìˆ í˜•/ê°íƒ„í˜•ì„ ë‹¤ì–‘í•˜ê²Œ í™œìš©
   - ë¹„ìœ ì™€ ì€ìœ  í‘œí˜„ ì¶”ê°€
   - ìˆ«ì í‘œí˜„ ë°©ì‹ ë³€ê²½ (ì˜ˆ: "30%" â†’ "10ëª… ì¤‘ 3ëª…")
8. **ê°ì • í†¤ ë³€ê²½**: ì›ë³¸ì˜ ê°ì •ì  í†¤ì„ ì™„ì „íˆ ë‹¤ë¥´ê²Œ ì„¤ì •
9. **ë…ì ê´€ì  ì „í™˜**: ë‹¤ë¥¸ ë…ìì¸µì—ê²Œ ë§í•˜ëŠ” ê²ƒì²˜ëŸ¼ í†¤ì•¤ë§¤ë„ˆ ë³€ê²½
10. **í•µì‹¬ ì‚¬ì‹¤ë§Œ ë³´ì¡´**: ë‚ ì§œ, ìˆ˜ì¹˜, ê³ ìœ ëª…ì‚¬, í•µì‹¬ ì‚¬ì‹¤ì€ ì •í™•íˆ ìœ ì§€

**êµµê²Œ í‘œì‹œ ìµœì†Œí™” (ì¤‘ìš”):**
- **í•µì‹¬ í‚¤ì›Œë“œ**ëŠ” ë¬¸ë‹¨ë‹¹ ìµœëŒ€ 1-2ê°œë§Œ **êµµê²Œ** í‘œì‹œ
- **ìˆ˜ì¹˜ë‚˜ ê¸°ì—…ëª…** ë“± ê¼­ í•„ìš”í•œ ì •ë³´ë§Œ **êµµê²Œ** ì²˜ë¦¬
- ê³¼ë„í•œ **êµµê²Œ** í‘œì‹œëŠ” í”¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì½íˆë„ë¡ ì‘ì„±
- **35-60ëŒ€ ë…ìì¸µ**ì´ ë¶€ë‹´ìŠ¤ëŸ½ì§€ ì•Šê²Œ ì ë‹¹íˆ ê°•ì¡°
- ë¬¸ë‹¨ë§ˆë‹¤ **êµµì€ í…ìŠ¤íŠ¸**ê°€ ì—†ì–´ë„ ê´œì°®ìŒ

**ë¬¸ì²´ ë³€í˜• ì˜ˆì‹œ:**
- ì›ë³¸: "íšŒì‚¬ê°€ ë°œí‘œí–ˆë‹¤" â†’ ë³€í˜•: "ì—…ì²´ ì¸¡ì´ ê³µê°œí•œ ë°”ì— ë”°ë¥´ë©´"
- ì›ë³¸: "ì¦ê°€í–ˆë‹¤" â†’ ë³€í˜•: "ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆë‹¤", "ëŠ˜ì–´ë‚˜ëŠ” ì¶”ì„¸ë‹¤"
- ì›ë³¸: "ë¬¸ì œê°€ ìˆë‹¤" â†’ ë³€í˜•: "ìš°ë ¤ìŠ¤ëŸ¬ìš´ ìƒí™©ì´ ë²Œì–´ì§€ê³  ìˆë‹¤"

**í—¤ë”© êµ¬ì¡° (ì ˆëŒ€ ì—„ìˆ˜):**
##### [ì²« ë²ˆì§¸ ì¤„ ìš”ì•½]<br>[ë‘ ë²ˆì§¸ ì¤„ ìš”ì•½]

**í—¤ë”© ì‚¬ìš© ê·œì¹™:**
- H5(#####): í•˜ë‚˜ì˜ íƒœê·¸ ì•ˆì— <br>ë¡œ ë‘ ì¤„ ì‘ì„± (| ì‘ëŒ€ê¸° ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
- H2(##): ëª¨ë“  ì†Œì œëª©ì— ì‚¬ìš© (H3, H4, H6 ì ˆëŒ€ ê¸ˆì§€!)
- H1(#): ì‚¬ìš© ê¸ˆì§€ (Hugoì—ì„œ ìë™ ìƒì„±)

**H2 ì†Œì œëª© ì‘ì„± ê·œì¹™:**
- ì½œë¡ (:), ëŠë‚Œí‘œ(!), ë¬¼ìŒí‘œ(?) ë“± íŠ¹ìˆ˜ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
- ìì—°ìŠ¤ëŸ¬ìš´ ëª…ì‚¬í˜• ë˜ëŠ” ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±
- ì˜ˆì‹œ: "ì£¼ìš” ë³€í™” ë™í–¥", "ì‹œì¥ ë°˜ì‘ê³¼ ì „ë§", "ì—…ê³„ ë¶„ì„ ê²°ê³¼"

**ê¸°ì‚¬ êµ¬ì¡° (ì ˆëŒ€ ì¤€ìˆ˜):**
1. H5 ìš”ì•½: ##### **ì²« ë²ˆì§¸ ì¤„**<br>**ë‘ ë²ˆì§¸ ì¤„**
2. ë„ì… ë³¸ë¬¸: 2-3ê°œ ë¬¸ë‹¨ (H2 ì—†ì´ ë°”ë¡œ ë³¸ë¬¸ìœ¼ë¡œ ì‹œì‘, ì ë‹¹í•œ ê°•ì¡°)
3. H2 ì†Œì œëª© + ë³¸ë¬¸ ë°˜ë³µ (ê³¼ë„í•œ **êµµê²Œ** í‘œì‹œ ê¸ˆì§€)

**H5 ìš”ì•½ í•„ìˆ˜ í˜•ì‹:**
##### **500ë§ˆë ¥ ì „ê¸° SUV êµ­ë‚´ ìƒë¥™ ì˜ˆê³ **<br>**ëŸ­ì…”ë¦¬ì™€ ì˜¤í”„ë¡œë“œ ëŠ¥ë ¥ ëª¨ë‘ ê°–ì¶°**

**ê¸°ì‚¬ ì‹œì‘ êµ¬ì¡° ì˜ˆì‹œ:**
##### **í•µì‹¬ ë‚´ìš© ìš”ì•½**<br>**ë¶€ê°€ ì„¤ëª… ìš”ì•½**

ì—…ê³„ì—ì„œëŠ” ì´ë²ˆ ë°œí‘œê°€ ì‹œì¥ì— í° ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ ê²ƒìœ¼ë¡œ ì „ë§í•˜ê³  ìˆë‹¤. 

ê´€ë ¨ ì „ë¬¸ê°€ë“¤ì€ ì´ëŸ¬í•œ ì›€ì§ì„ì´ í–¥í›„ ì—…ê³„ ì „ë°˜ì— ë¯¸ì¹  íŒŒê¸‰íš¨ê³¼ë¥¼ ì£¼ëª©í•˜ê³  ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ë¶„ì„ì´ ì œê¸°ë˜ê³  ìˆëŠ” ìƒí™©ì´ë‹¤.

íŠ¹íˆ ì´ë²ˆ ì‚¬ì•ˆì€ ê¸°ì¡´ ì‹œì¥ êµ¬ì¡°ì— ìƒˆë¡œìš´ ë³€ìˆ˜ë¡œ ì‘ìš©í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, ê´€ë ¨ ê¸°ì—…ë“¤ì˜ **ëŒ€ì‘ ì „ëµ**ì—ë„ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆë‹¤.

## ì£¼ìš” ë³€í™” ë™í–¥

(ì´í›„ H2 + ë³¸ë¬¸ ë°˜ë³µ, **êµµê²Œ** í‘œì‹œëŠ” ê¼­ í•„ìš”í•œ ê³³ì—ë§Œ ìµœì†Œí•œìœ¼ë¡œ...)

**ìµœì¢… ëª©í‘œ: ì›ë³¸ ì‘ì„±ìê°€ "ì´ê±´ ë‚´ ê¸€ì´ ì•„ë‹ˆì•¼!"ë¼ê³  í•  ì •ë„ë¡œ ì™„ì „íˆ ë‹¤ë¥¸ ì‘í’ˆì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.**
ê°™ì€ ì‚¬ê±´ì„ ë‹¤ë£¬ ì „í˜€ ë‹¤ë¥¸ ê¸°ìì˜ ë…ë¦½ì ì¸ ì·¨ì¬ ê¸°ì‚¬ì²˜ëŸ¼ ì‘ì„±í•´ì£¼ë˜, **êµµê²Œ í‘œì‹œëŠ” ìµœì†Œí™”**í•˜ì—¬ 35-60ëŒ€ ë…ìì¸µì´ **ìì—°ìŠ¤ëŸ½ê²Œ ì½ì„ ìˆ˜ ìˆë„ë¡** í•´ì£¼ì„¸ìš”.
"""
                
                response = client.chat.completions.create(
                    model="gpt-4.1",  # gpt-4o-mini â†’ gpt-4.1ë¡œ ë³€ê²½
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì°½ì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì™„ì „íˆ ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ë¡œ ë³€í˜•í•˜ì—¬ ì›ì €ì‘ìë„ ì¸ì‹í•  ìˆ˜ ì—†ê²Œ ë§Œë“œëŠ” ì¬ì°½ì‘ì˜ ë‹¬ì¸ì…ë‹ˆë‹¤. ê°™ì€ ì‚¬ì‹¤ì„ ì „í˜€ ë‹¤ë¥¸ í‘œí˜„ê³¼ êµ¬ì¡°ë¡œ ì¬íƒ„ìƒì‹œí‚¤ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ íŠ¹ê¸°ì…ë‹ˆë‹¤. ë¬¸ì²´, í†¤, êµ¬ì¡°, í‘œí˜„ì„ í˜ì‹ ì ìœ¼ë¡œ ë°”ê¿”ì„œ ì™„ì „íˆ ìƒˆë¡œìš´ ì‘í’ˆì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. êµµê²Œ í‘œì‹œëŠ” ê¼­ í•„ìš”í•œ ê³³ì—ë§Œ ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì½íˆë„ë¡ í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2000,
                    temperature=0.8
                )
                
                rewritten = response.choices[0].message.content.strip()
                # YAML ì•ˆì „ì„±ì„ ìœ„í•´ YAML êµ¬ë¶„ìë§Œ ì •ë¦¬ (ë”°ì˜´í‘œëŠ” ë³´ì¡´)
                rewritten = rewritten.replace('```', '').replace('---', 'â€”')  # YAML êµ¬ë¶„ì ë¬¸ì œ ë°©ì§€
                print(f"âœ… AI rewrite successful on attempt {attempt + 1}")
                return rewritten
                
        except Exception as e:
            print(f"âŒ AI rewrite attempt {attempt + 1} failed: {e}")
            if attempt < 2:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
                time.sleep(2)  # 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                continue
            else:
                print("ğŸš¨ All AI rewrite attempts failed - raising exception")
                raise Exception(f"AI rewrite failed after 3 attempts: {e}")
    
    raise Exception("AI rewrite failed - unexpected end of function")

def generate_ai_tags(title, content, existing_tags, api_key, api_type="openai"):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ íƒœê·¸ ìƒì„±"""
    if not api_key:
        print("âš ï¸ No AI API key - using default tags")
        return existing_tags + ["ë‰´ìŠ¤", "ì´ìŠˆ"]
    
    for attempt in range(3):
        try:
            print(f"ğŸ·ï¸ AI tag generation attempt {attempt + 1}/3...")
            if api_type == "openai" and HAS_OPENAI:
                client = OpenAI(api_key=api_key)
                
                prompt = f"""
ê¸°ì‚¬ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ **ë…ì°½ì ì´ê³  ì°¨ë³„í™”ëœ** íƒœê·¸ 2ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ê¸°ì¡´ íƒœê·¸ì™€ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì ‘ê·¼í•´ì£¼ì„¸ìš”.

ì œëª©: {title}
ë‚´ìš©: {content[:500]}...
ê¸°ì¡´ íƒœê·¸: {', '.join(existing_tags)}

**ì°½ì˜ì  íƒœê·¸ ìƒì„± ìš”êµ¬ì‚¬í•­:**
1. ê¸°ì¡´ íƒœê·¸ì™€ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ê´€ì 
2. í•´ë‹¹ ì—…ê³„ì˜ ì „ë¬¸ ìš©ì–´ë‚˜ íŠ¸ë Œë“œ ë°˜ì˜
3. ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ í™œìš© ê°€ëŠ¥í•œ ì‹¤ìš©ì  íƒœê·¸
4. 35~60ëŒ€ ë…ìì¸µì´ ê´€ì‹¬ ê°€ì§ˆë§Œí•œ ì£¼ì œ

**íƒœê·¸ ìŠ¤íƒ€ì¼ ì˜ˆì‹œ:**
- "ë¯¸ë˜ì „ë§", "ì—…ê³„ë™í–¥", "ì „ë¬¸ê°€ë¶„ì„", "ì‹œì¥ë³€í™”"
- "íˆ¬ìí¬ì¸íŠ¸", "ì†Œë¹„íŠ¸ë Œë“œ", "ê¸°ìˆ í˜ì‹ ", "ì •ì±…ì˜í–¥"

JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µ: ["íƒœê·¸1", "íƒœê·¸2"]
"""
                
                response = client.chat.completions.create(
                    model="gpt-4.1",  # gpt-4o-mini â†’ gpt-4.1ë¡œ ë³€ê²½
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì°½ì˜ì  íƒœê·¸ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì¡´ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ê´€ì ì—ì„œ ë…ì°½ì ì´ê³  ì°¨ë³„í™”ëœ íƒœê·¸ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ë§ˆì¼€íŒ… ì „ëµê°€ì…ë‹ˆë‹¤. ë…ìì˜ ê´€ì‹¬ì„ ëŒê³  ê²€ìƒ‰ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ” í˜ì‹ ì ì¸ íƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=100,
                    temperature=0.7
                )
                
                result = response.choices[0].message.content.strip()
                # JSON íŒŒì‹± ì‹œë„
                try:
                    new_tags = json.loads(result)
                    if isinstance(new_tags, list) and len(new_tags) >= 2:
                        print(f"âœ… AI tag generation successful on attempt {attempt + 1}")
                        return existing_tags + new_tags[:2]
                except:
                    pass
                    
        except Exception as e:
            print(f"âŒ AI tag generation attempt {attempt + 1} failed: {e}")
            if attempt < 2:
                time.sleep(1)
                continue
            else:
                print("âš ï¸ All AI tag attempts failed - using default tags")
                return existing_tags + ["ë‰´ìŠ¤", "ì´ìŠˆ"]
    
    return existing_tags + ["ë‰´ìŠ¤", "ì´ìŠˆ"]

def rewrite_title_with_ai(original_title, content, api_key, api_type="openai"):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì œëª© ì¬ì‘ì„± (êµ¬ì¡° ìœ ì§€, ë‚´ìš© ë³€ê²½)"""
    if not api_key:
        print("âš ï¸ No AI API key provided, keeping original title")
        return original_title
    
    for attempt in range(3):
        try:
            print(f"ğŸ“ AI title rewrite attempt {attempt + 1}/3...")
            if api_type == "openai" and HAS_OPENAI:
                client = OpenAI(api_key=api_key)
                
                # ë”°ì˜´í‘œ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                has_quotes = '"' in original_title or "'" in original_title
                
                if has_quotes:
                    prompt = f"""
ì›ë³¸ ì œëª©ì˜ **ì •í™•í•œ êµ¬ì¡°ì™€ ë¬¸ë²•ì„ 100% ì™„ë²½í•˜ê²Œ ìœ ì§€**í•˜ë˜, ë³¸ë¬¸ ë‚´ìš©ì— ë§ê²Œ **ë”°ì˜´í‘œ ì•ˆì˜ í•µì‹¬ ë‚´ìš©ë§Œ ë³€ê²½**í•´ì£¼ì„¸ìš”.

ì›ë³¸ ì œëª©: {original_title}

ë³¸ë¬¸ ë‚´ìš© (í•µì‹¬ë§Œ):
{content[:1000]}...

**ì ˆëŒ€ ì—„ìˆ˜ ìš”êµ¬ì‚¬í•­:**
1. **ë”°ì˜´í‘œ ì™„ì „ ë³´ì¡´**: "í°ë”°ì˜´í‘œ", 'ì‘ì€ë”°ì˜´í‘œ' ê°œìˆ˜ì™€ ìœ„ì¹˜ ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€
2. **êµ¬ë‘ì  ì™„ì „ ë³´ì¡´**: ëª¨ë“  ê¸°í˜¸ ê·¸ëŒ€ë¡œ
3. **ì¡°ì‚¬/ì–´ë¯¸ ì™„ì „ ë³´ì¡´**: ëª¨ë“  ì¡°ì‚¬ì™€ ì–´ë¯¸ ê·¸ëŒ€ë¡œ
4. **ë”°ì˜´í‘œ ì•ˆì˜ ë‚´ìš©ë§Œ ë³€ê²½** í—ˆìš©

ë³¸ë¬¸ ë‚´ìš©ì— ë§ëŠ” ì œëª©ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
"""
                else:
                    prompt = f"""
ì›ë³¸ ì œëª©ì˜ **ì •í™•í•œ êµ¬ì¡°ì™€ ë¬¸ë²•ì„ ìœ ì§€**í•˜ë˜, ë³¸ë¬¸ ë‚´ìš©ì— ë§ê²Œ **í•µì‹¬ í‚¤ì›Œë“œë§Œ ë³€ê²½**í•´ì£¼ì„¸ìš”.

ì›ë³¸ ì œëª©: {original_title}

ë³¸ë¬¸ ë‚´ìš© (í•µì‹¬ë§Œ):
{content[:1000]}...

**ìš”êµ¬ì‚¬í•­:**
1. **ë”°ì˜´í‘œ ì¶”ê°€ ê¸ˆì§€**: ì›ë³¸ì— ì—†ëŠ” ë”°ì˜´í‘œëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
2. **êµ¬ì¡° ìœ ì§€**: ì›ë³¸ê³¼ ê°™ì€ ë¬¸ì¥ êµ¬ì¡° ìœ ì§€
3. **í‚¤ì›Œë“œ ë³€ê²½**: ë³¸ë¬¸ ë‚´ìš©ì— ë§ëŠ” í‚¤ì›Œë“œë¡œë§Œ ë³€ê²½
4. **ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´**: ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ì œëª©

**ì˜ˆì‹œ:**
ì›ë³¸: ë„ë£¨ë¬µ ì œì²  ë‚˜ì˜¤ëŠ” ì‹œê¸° ë„ë£¨ë¬µì˜ íš¨ëŠ¥ ìš”ë¦¬ë²• ë³´ê´€ë²•
ë³€ê²½: ê°ˆì¹˜ ì œì²  ë‚˜ì˜¤ëŠ” ì‹œê¸° ê°ˆì¹˜ì˜ íš¨ëŠ¥ ìš”ë¦¬ë²• ë³´ê´€ë²•

ë³¸ë¬¸ ë‚´ìš©ì— ë§ëŠ” ì œëª©ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
"""
                
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì œëª© êµ¬ì¡° ë³´ì¡´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì›ë³¸ ì œëª©ì˜ ì •í™•í•œ ë¬¸ë²•ê³¼ êµ¬ì¡°ë¥¼ 100% ìœ ì§€í•˜ë©´ì„œ ë‚´ìš©ë§Œ ë³€ê²½í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤. íŠ¹íˆ ë”°ì˜´í‘œëŠ” ì ˆëŒ€ ëˆ„ë½ì‹œí‚¤ë©´ ì•ˆ ë©ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=200,
                    temperature=0.2  # ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
                )
                
                rewritten_title = response.choices[0].message.content.strip()
                
                # ë”°ì˜´í‘œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì—„ê²©í•œ ê²€ì¦
                if has_quotes:
                    original_double_quotes = original_title.count('"')
                    original_single_quotes = original_title.count("'")
                    rewritten_double_quotes = rewritten_title.count('"')
                    rewritten_single_quotes = rewritten_title.count("'")
                    
                    if (original_double_quotes != rewritten_double_quotes or 
                        original_single_quotes != rewritten_single_quotes):
                        print(f"âš ï¸ ë”°ì˜´í‘œ ê°œìˆ˜ ë¶ˆì¼ì¹˜ (ì‹œë„ {attempt + 1}): ì›ë³¸ \"{original_double_quotes}, '{original_single_quotes} vs ì¬ì‘ì„± \"{rewritten_double_quotes}, '{rewritten_single_quotes}, ì¬ì‹œë„...")
                        continue
                else:
                    # ë”°ì˜´í‘œê°€ ì—†ëŠ” ì œëª©: ìƒˆë¡œìš´ ë”°ì˜´í‘œê°€ ì¶”ê°€ë˜ì§€ ì•Šì•˜ëŠ”ì§€ë§Œ í™•ì¸
                    rewritten_double_quotes = rewritten_title.count('"')
                    rewritten_single_quotes = rewritten_title.count("'")
                    
                    if rewritten_double_quotes > 0 or rewritten_single_quotes > 0:
                        print(f"âš ï¸ ì›ë³¸ì— ì—†ë˜ ë”°ì˜´í‘œ ì¶”ê°€ë¨ (ì‹œë„ {attempt + 1}): ì¬ì‘ì„±ì— \"{rewritten_double_quotes}, '{rewritten_single_quotes} ë°œê²¬, ì¬ì‹œë„...")
                        continue
                
                # ë”°ì˜´í‘œê°€ ìˆëŠ” ì œëª©ì—ë§Œ ì—„ê²©í•œ êµ¬ì¡° ê²€ì¦ ì ìš©
                if has_quotes:
                    structure_words = ["ë‹¤ë”ë‹ˆ", "ë¼ë”ë‹ˆ", "ì—ì„œ", "ë“œëŸ¬ë‚œ", "ì˜", "ë¡œ", "ìœ¼ë¡œ", "ì›”ì„¸ë¡œ"]
                    original_structure = [word for word in structure_words if word in original_title]
                    rewritten_structure = [word for word in structure_words if word in rewritten_title]
                    
                    if set(original_structure) != set(rewritten_structure):
                        print(f"âš ï¸ êµ¬ì¡° ë‹¨ì–´ ë¶ˆì¼ì¹˜ (ì‹œë„ {attempt + 1}): ì›ë³¸ {original_structure} vs ì¬ì‘ì„± {rewritten_structure}, ì¬ì‹œë„...")
                        continue
                
                # ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ê²€ì¦ (ëª¨ë“  ì œëª©ì— ì ìš©)
                unnatural_patterns = [" ì´ ì•ˆ", " ê°€ ì•ˆ", " ì„ ì•ˆ", " ë¥¼ ì•ˆ"]
                if any(pattern in rewritten_title for pattern in unnatural_patterns):
                    print(f"âš ï¸ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ê°ì§€ (ì‹œë„ {attempt + 1}), ì¬ì‹œë„...")
                    continue
                
                print(f"âœ… ì œëª© ì¬ì‘ì„± ì„±ê³µ: {rewritten_title}")
                return rewritten_title
            else:
                print(f"âš ï¸ OpenAI not available or wrong API type: {api_type}")
                return original_title
            
        except Exception as e:
            print(f"âš ï¸ Title rewrite attempt {attempt + 1} failed: {e}")
    
    print("âš ï¸ AI title rewrite failed after 3 attempts, keeping original")
    return original_title

def extract_content_from_url(url):
    """í‹°ìŠ¤í† ë¦¬ URLì—ì„œ ì½˜í…ì¸  ì¶”ì¶œ"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # í‹°ìŠ¤í† ë¦¬ ì œëª© ì¶”ì¶œ
        title = None
        title_selectors = [
            'h1.title_post',
            'h1.post-title', 
            '.title_post',
            'h1',
            'title'
        ]
        
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text().strip()
                break
        
        if not title:
            title = "ì œëª© ì—†ìŒ"
        
        # ì‘ì„±ì ì •ë³´ (AI ì¬ì‘ì„±ìš©)
        author = "ìœ¤ì‹ ì• "  # AI ì¬ì‘ì„± ê¸€ ì‘ì„±ì
        
        # ê¸°ë³¸ íƒœê·¸ ì„¤ì •
        tags = ["ë‰´ìŠ¤", "ì´ìŠˆ"]  # ê¸°ë³¸ íƒœê·¸
        
        # í‹°ìŠ¤í† ë¦¬ ë‚´ìš© ì¶”ì¶œ
        content_elem = soup.find('div', class_='entry-content')
        if not content_elem:
            # ë‹¤ë¥¸ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ëª…ë“¤ ì‹œë„
            content_selectors = [
                '.article_view',
                '.post-content',
                '.contents_style',
                '.post_ct'
            ]
            
            for selector in content_selectors:
                content_elem = soup.select_one(selector)
                if content_elem:
                    break
        
        if not content_elem:
            return None
        
        # í‹°ìŠ¤í† ë¦¬ ê´‘ê³  ë° ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°
        for unwanted in content_elem.select('script, style, ins.adsbygoogle, .revenue_unit_wrap, .google-auto-placed'):
            unwanted.decompose()
        
        # í‹°ìŠ¤í† ë¦¬ ê´‘ê³  div ì œê±°
        for ad_div in content_elem.find_all('div'):
            if ad_div.get('data-tistory-react-app'):
                ad_div.decompose()
        
        # ì´ë¯¸ì§€ URL ìˆ˜ì§‘ (í‹°ìŠ¤í† ë¦¬ ì´ë¯¸ì§€)
        images = []
        for img in content_elem.find_all('img'):
            img_src = img.get('src')
            if img_src:
                # ì ˆëŒ€ URLë¡œ ë³€í™˜
                if img_src.startswith('//'):
                    img_src = 'https:' + img_src
                elif img_src.startswith('/'):
                    img_src = 'https://difks2004.tistory.com' + img_src
                elif not img_src.startswith('http'):
                    img_src = 'https://difks2004.tistory.com/' + img_src
                images.append(img_src)
        
        # ì›ë³¸ ì´ë¯¸ì§€ ìˆœì„œë¥¼ ì™„ì „íˆ ì„ì–´ì„œ ë°°ì¹˜ (ì›ë³¸ê³¼ ë‹¤ë¥´ê²Œ)
        import random
        if images:
            random.shuffle(images)  # ì´ë¯¸ì§€ ìˆœì„œ ë¬´ì‘ìœ„ë¡œ ì„ê¸°
        
        # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ (ì´ë¯¸ì§€ ì™„ì „ ì œê±° - ì›ë³¸ ìœ„ì¹˜ ì •ë³´ ì‚­ì œ)
        paragraphs = []
        for elem in content_elem.children:
            if hasattr(elem, 'name') and elem.name:
                if elem.name in ['p', 'h1', 'h2', 'h3', 'h4', 'h5']:
                    # ì´ë¯¸ì§€ íƒœê·¸ ì™„ì „ ì œê±° (ì›ë³¸ ìœ„ì¹˜ ì •ë³´ ì‚­ì œ)
                    for img in elem.find_all('img'):
                        img.decompose()
                    
                    # í”¼ê²¨ íƒœê·¸ë„ ì œê±° (ì´ë¯¸ì§€ ìº¡ì…˜ í¬í•¨)
                    for figure in elem.find_all('figure'):
                        figure.decompose()
                        
                    # <br> íƒœê·¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜
                    for br in elem.find_all('br'):
                        br.replace_with('\n')
                    
                    text = elem.get_text().strip()
                    # ì´ë¯¸ì§€ ê´€ë ¨ í…ìŠ¤íŠ¸ íŒ¨í„´ ì œê±°
                    text = re.sub(r'\[ì´ë¯¸ì§€.*?\]', '', text)
                    text = re.sub(r'\(ì‚¬ì§„.*?\)', '', text)
                    text = re.sub(r'ì‚¬ì§„=.*', '', text)
                    text = re.sub(r'ì´ë¯¸ì§€=.*', '', text)
                    
                    if text and not text.startswith('(adsbygoogle'):
                        if elem.name in ['h2', 'h3', 'h4', 'h5']:
                            # ì†Œì œëª©ì—ì„œ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
                            clean_text = text.replace(':', '').replace('!', '').replace('?', '').replace('|', '').strip()
                            paragraphs.append(f"\n## {clean_text}\n")  # H2ë¡œ ë³€í™˜
                        else:
                            paragraphs.append(text)
        
        content = '\n\n'.join(paragraphs)
        
        # ìš”ì•½ë¬¸ ìƒì„± (YAML safe - ë”°ì˜´í‘œ ë³´ì¡´)
        if paragraphs:
            description = paragraphs[0][:150] + "..."
            # YAML ì•ˆì „ì„±ì„ ìœ„í•œ ê¸°ë³¸ ì •ë¦¬ (ë”°ì˜´í‘œëŠ” HTML ì—”í‹°í‹°ë¡œ ë³´ì¡´)
            description = description.replace('"', '&quot;').replace('\n', ' ').replace('\r', ' ')
            description = re.sub(r'\s+', ' ', description).strip()
        else:
            description = ""
        
        return {
            'title': title,
            'description': description,
            'content': content,
            'images': images,
            'url': url,
            'author': author,
            'tags': tags
        }
    
    except Exception as e:
        print(f"âŒ Error extracting content from {url}: {e}")
        return None

def analyze_image_text_content(image_url, api_key):
    """AI Visionìœ¼ë¡œ ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ ë¶„ì„ (ë‰´ìŠ¤ ê´€ë ¨ ì´ë¯¸ì§€ ì œì™¸)"""
    if not api_key:
        return False  # API í‚¤ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì—†ë‹¤ê³  ê°€ì •
    
    try:
        if HAS_OPENAI:
            client = OpenAI(api_key=api_key)
            
            # GPT-4.1ë¡œ ë¨¼ì € ì‹œë„, ì‹¤íŒ¨í•˜ë©´ gpt-4o ì‚¬ìš©
            models_to_try = ["gpt-4.1", "gpt-4o"]
            
            for model in models_to_try:
                try:
                    response = client.chat.completions.create(
                        model=model,
                        messages=[
                            {
                                "role": "user",
                                "content": [
                                    {
                                        "type": "text",
                                        "text": "ì´ ì´ë¯¸ì§€ë¥¼ ë§¤ìš° ì—„ê²©í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\në‰´ìŠ¤ ê´€ë ¨ í…ìŠ¤íŠ¸ ì²´í¬ (ìš°ì„ ìˆœìœ„):\n- 'ì—°í•©ë‰´ìŠ¤', 'ë‰´ìŠ¤1', 'YONHAP', 'NEWS', 'SBS', 'KBS', 'MBC', 'JTBC' ë“± ì–¸ë¡ ì‚¬ëª…\n- 'ê¸°ì', 'ì œê³µ', 'ì¶œì²˜', 'ì·¨ì¬', 'ë³´ë„' ë“± ë‰´ìŠ¤ ê´€ë ¨ ë‹¨ì–´\n- ë‰´ìŠ¤ ë¡œê³ , ì›Œí„°ë§ˆí¬, ë°©ì†¡êµ­ ì‹¬ë³¼\n- ê¸°ì‚¬ ìº¡ì…˜, ë‰´ìŠ¤ í™”ë©´ ìº¡ì²˜\n\nì¼ë°˜ í…ìŠ¤íŠ¸ ì²´í¬:\n- í•œê¸€, ì˜ì–´, ìˆ«ìê°€ í¬í•¨ëœ ê²½ìš°\n- ìƒí’ˆëª…, ë¸Œëœë“œëª…, ê°€ê²© í‘œì‹œ\n- ê´‘ê³  ë¬¸êµ¬, ì„¤ëª… í…ìŠ¤íŠ¸\n\në§¤ìš° ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì—¬:\n- ë‰´ìŠ¤ ê´€ë ¨ì´ ì¡°ê¸ˆì´ë¼ë„ ìˆìœ¼ë©´: 'NEWS_TEXT'\n- ê¸°íƒ€ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´: 'HAS_TEXT'  \n- ì™„ì „íˆ í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´: 'NO_TEXT'\n\ní•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                                    },
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": image_url
                                        }
                                    }
                                ]
                            }
                        ],
                        max_tokens=20
                    )
                    
                    result = response.choices[0].message.content.strip().upper()
                    
                    # ë‰´ìŠ¤ ê´€ë ¨ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì œì™¸ (True ë°˜í™˜ = í…ìŠ¤íŠ¸ ìˆìŒ)
                    if "NEWS_TEXT" in result:
                        print(f"ğŸš« ë‰´ìŠ¤ ê´€ë ¨ í…ìŠ¤íŠ¸ ê°ì§€ë¡œ ì œì™¸ ({model}): {image_url[:50]}...")
                        return True  # í…ìŠ¤íŠ¸ ìˆìŒìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì œì™¸
                    
                    # ê¸°íƒ€ í…ìŠ¤íŠ¸ í™•ì¸
                    has_text = "HAS_TEXT" in result
                    print(f"ğŸ” ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ë¶„ì„ ({model}): {image_url[:50]}... â†’ {'í…ìŠ¤íŠ¸ ìˆìŒ' if has_text else 'í…ìŠ¤íŠ¸ ì—†ìŒ'}")
                    return has_text
                    
                except Exception as model_error:
                    if "gpt-4.1" in model:
                        print(f"âš ï¸ {model} Vision ì§€ì› ì•ˆí•¨, gpt-4oë¡œ ì¬ì‹œë„...")
                        continue  # ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                    else:
                        print(f"âš ï¸ {model} ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {model_error}")
                        break  # gpt-4oë„ ì‹¤íŒ¨í•˜ë©´ ì¢…ë£Œ
            
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return False  # ë¶„ì„ ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ì—†ë‹¤ê³  ê°€ì •
    
    return False

def generate_contextual_alt_text(paragraph_text, title, api_key):
    """ë¬¸ë§¥ì— ë§ëŠ” alt í…ìŠ¤íŠ¸ AI ìƒì„±"""
    if not api_key:
        return "ê¸°ì‚¬ ê´€ë ¨ ì´ë¯¸ì§€"
    
    try:
        if HAS_OPENAI:
            client = OpenAI(api_key=api_key)
            
            prompt = f"""
ë‹¤ìŒ ê¸°ì‚¬ì˜ ì œëª©ê³¼ ë¬¸ë‹¨ì„ ë³´ê³ , ì´ ìœ„ì¹˜ì— ë“¤ì–´ê°ˆ ì´ë¯¸ì§€ì˜ alt í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì´ë¯¸ì§€ê°€ ë³¸ë¬¸ ë‚´ìš©ê³¼ ê´€ë ¨ì„±ì´ ë†’ë„ë¡ ì˜ë¯¸ ìˆëŠ” alt í…ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê¸°ì‚¬ ì œëª©: {title}
í•´ë‹¹ ë¬¸ë‹¨: {paragraph_text[:200]}...

ìš”êµ¬ì‚¬í•­:
1. ë³¸ë¬¸ ë‚´ìš©ê³¼ ì—°ê´€ì„± ìˆëŠ” alt í…ìŠ¤íŠ¸
2. SEOì— ë„ì›€ì´ ë˜ëŠ” í‚¤ì›Œë“œ í¬í•¨
3. 10-15ì ë‚´ì™¸ì˜ ê°„ê²°í•œ í…ìŠ¤íŠ¸
4. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„
5. **35~60ëŒ€ ë…ìì¸µì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ìš©ì–´ ì‚¬ìš©**

alt í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
"""
            
            response = client.chat.completions.create(
                model="gpt-4.1",  # gpt-4o-mini â†’ gpt-4.1ë¡œ ë³€ê²½
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³¸ë¬¸ ë‚´ìš©ê³¼ ì˜ ì–´ìš¸ë¦¬ëŠ” ì´ë¯¸ì§€ alt í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=50,
                temperature=0.7
            )
            
            alt_text = response.choices[0].message.content.strip()
            # ë”°ì˜´í‘œ ì œê±° ë° ì •ë¦¬
            alt_text = alt_text.strip('"').strip("'").strip()
            return alt_text if alt_text else "ê¸°ì‚¬ ê´€ë ¨ ì´ë¯¸ì§€"
    except:
        pass
    
    return "ê¸°ì‚¬ ê´€ë ¨ ì´ë¯¸ì§€"

def generate_article_html(article_data, cloudflare_images=None):
    """í‹°ìŠ¤í† ë¦¬ í¬ìŠ¤íŒ…ìš© HTML ìƒì„±"""
    title = article_data.get('title', 'ì œëª© ì—†ìŒ')
    safe_title = title.replace(" ", "_")
    content = article_data.get('content', '')
    tags = article_data.get('tags', [])
    original_url = article_data.get('url', '')
    
    # f-stringì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ ì²˜ë¦¬
    backslash = chr(92)
    
    # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ì¸ë„¤ì¼ë¡œ ì‚¬ìš©
    thumbnail_img = ""
    if cloudflare_images:
        thumbnail_img = f'<img src="{cloudflare_images[0]}" alt="ì¸ë„¤ì¼" style="max-width:100%;height:auto;margin-bottom:20px;">'
    
    # ë³¸ë¬¸ì— ì´ë¯¸ì§€ ì‚½ì… (ëœë¤ ìœ„ì¹˜)
    content_with_images = content
    if cloudflare_images and len(cloudflare_images) > 1:
        # H2 íƒœê·¸ ë’¤ì— ì´ë¯¸ì§€ ì‚½ì…
        import re
        h2_pattern = r'(## [^\n]+)'
        def replace_h2_with_image(match):
            nonlocal cloudflare_images
            if len(cloudflare_images) > 1:
                img_url = cloudflare_images.pop(1)  # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ë¶€í„° ì‚¬ìš©
                return f'{match.group(1)}\n\n<img src="{img_url}" alt="ê´€ë ¨ ì´ë¯¸ì§€" style="max-width:100%;height:auto;margin:20px 0;">\n'
            return match.group(1)
        
        content_with_images = re.sub(h2_pattern, replace_h2_with_image, content_with_images)
    
    # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜
    html_content = convert_markdown_to_html(content_with_images)
    
    # ì™„ì „í•œ HTML í˜ì´ì§€ ìƒì„±
    full_html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; line-height: 1.6; }}
        h1 {{ color: #333; border-bottom: 2px solid #007acc; padding-bottom: 10px; }}
        h2 {{ color: #555; margin-top: 30px; }}
        h5 {{ background: #f8f9fa; padding: 15px; border-left: 4px solid #007acc; margin: 20px 0; }}
        .tags {{ background: #f1f3f4; padding: 10px; border-radius: 5px; margin: 20px 0; }}
        .tag {{ display: inline-block; background: #007acc; color: white; padding: 3px 8px; margin: 2px; border-radius: 3px; font-size: 12px; }}
        .original-url {{ color: #666; font-size: 12px; margin-top: 20px; }}
        .copy-btn {{ background: #007acc; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; margin: 10px 5px 0 0; }}
        .copy-btn:hover {{ background: #005a9e; }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    
    {thumbnail_img}
    
    <div class="content">
        {html_content}
    </div>
    
    <div class="tags">
        <strong>íƒœê·¸:</strong>
        {' '.join([f'<span class="tag">{tag}</span>' for tag in tags])}
    </div>
    
    <div class="original-url">
        <strong>ì›ë³¸ URL:</strong> <a href="{original_url}" target="_blank">{original_url}</a>
    </div>
    
    <button class="copy-btn" onclick="copyContent()">í‹°ìŠ¤í† ë¦¬ìš© HTML ë³µì‚¬</button>
    <button class="copy-btn" onclick="downloadHtml()">HTML íŒŒì¼ ë‹¤ìš´ë¡œë“œ</button>
    
    <script>
        function copyContent() {{
            const content = `{html_content.replace('`', backslash + '`')}`;
            navigator.clipboard.writeText(content).then(() => {{
                alert('í‹°ìŠ¤í† ë¦¬ìš© HTMLì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!');
            }});
        }}
        
        function downloadHtml() {{
            const content = document.documentElement.outerHTML;
            const blob = new Blob([content], {{ type: 'text/html' }});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = '{safe_title}.html';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }}
    </script>
</body>
</html>"""
    
    return full_html

def generate_index_html(articles_info):
    """ì „ì²´ ê¸€ ëª©ë¡ì„ ë³´ì—¬ì£¼ëŠ” ì¸ë±ìŠ¤ í™ˆí˜ì´ì§€ ìƒì„±"""
    articles_html = ""
    base_url = "https://12345-82w.pages.dev"
    
    for i, article in enumerate(articles_info, 1):
        title = article.get('title', 'ì œëª© ì—†ìŒ')
        filename = article.get('filename', '')
        tags = article.get('tags', [])
        thumbnail = article.get('thumbnail', '')
        
        thumbnail_img = ""
        if thumbnail:
            thumbnail_img = f'<img src="{thumbnail}" alt="ì¸ë„¤ì¼" style="width:200px;height:120px;object-fit:cover;border-radius:8px;">'
        
        articles_html += f"""
        <div class="article-card">
            <div class="article-thumbnail">
                {thumbnail_img}
            </div>
            <div class="article-info">
                <h3><a href="{base_url}/{filename}" target="_blank">{title}</a></h3>
                <div class="article-tags">
                    {' '.join([f'<span class="tag">{tag}</span>' for tag in tags[:3]])}
                </div>
                <div class="article-actions">
                    <a href="{base_url}/{filename}" class="btn-view" target="_blank">ë¯¸ë¦¬ë³´ê¸°</a>
                    <button class="btn-copy" onclick="copyArticleUrl('{filename}')">ë§í¬ ë³µì‚¬</button>
                </div>
            </div>
        </div>
        """
    
    index_html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI ì¬ì‘ì„± ê¸€ ëª©ë¡ - í‹°ìŠ¤í† ë¦¬ í¬ìŠ¤íŒ…ìš©</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
            background: #f8f9fa; 
            color: #333;
            line-height: 1.6;
        }}
        .header {{ 
            background: linear-gradient(135deg, #007acc 0%, #005a9e 100%); 
            color: white; 
            padding: 40px 20px; 
            text-align: center; 
        }}
        .header h1 {{ font-size: 2.5rem; margin-bottom: 10px; }}
        .header p {{ font-size: 1.1rem; opacity: 0.9; }}
        .container {{ max-width: 1200px; margin: 0 auto; padding: 40px 20px; }}
        .stats {{ 
            display: flex; 
            justify-content: center; 
            gap: 40px; 
            margin-bottom: 40px; 
            flex-wrap: wrap;
        }}
        .stat-card {{ 
            background: white; 
            padding: 20px; 
            border-radius: 10px; 
            box-shadow: 0 2px 10px rgba(0,0,0,0.1); 
            text-align: center; 
            min-width: 150px;
        }}
        .stat-number {{ font-size: 2rem; font-weight: bold; color: #007acc; }}
        .stat-label {{ color: #666; margin-top: 5px; }}
        .articles-grid {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fill, minmax(400px, 1fr)); 
            gap: 20px; 
        }}
        .article-card {{ 
            background: white; 
            border-radius: 12px; 
            box-shadow: 0 4px 15px rgba(0,0,0,0.1); 
            overflow: hidden; 
            transition: transform 0.2s, box-shadow 0.2s; 
            display: flex;
            flex-direction: row;
        }}
        .article-card:hover {{ 
            transform: translateY(-2px); 
            box-shadow: 0 8px 25px rgba(0,0,0,0.15); 
        }}
        .article-thumbnail {{ 
            flex-shrink: 0; 
            width: 200px; 
            height: 120px; 
            background: #f1f3f4; 
            display: flex; 
            align-items: center; 
            justify-content: center;
        }}
        .article-info {{ 
            padding: 20px; 
            flex: 1; 
            display: flex; 
            flex-direction: column; 
            justify-content: space-between;
        }}
        .article-info h3 {{ 
            margin-bottom: 10px; 
            line-height: 1.4;
        }}
        .article-info h3 a {{ 
            color: #333; 
            text-decoration: none; 
            font-size: 1.1rem;
        }}
        .article-info h3 a:hover {{ color: #007acc; }}
        .article-tags {{ margin-bottom: 15px; }}
        .tag {{ 
            display: inline-block; 
            background: #e9f4ff; 
            color: #007acc; 
            padding: 3px 8px; 
            margin: 2px; 
            border-radius: 4px; 
            font-size: 11px; 
            font-weight: 500;
        }}
        .article-actions {{ display: flex; gap: 10px; }}
        .btn-view, .btn-copy {{ 
            padding: 8px 16px; 
            border: none; 
            border-radius: 6px; 
            cursor: pointer; 
            font-size: 12px; 
            font-weight: 500; 
            text-decoration: none; 
            transition: all 0.2s;
        }}
        .btn-view {{ 
            background: #007acc; 
            color: white; 
        }}
        .btn-view:hover {{ background: #005a9e; }}
        .btn-copy {{ 
            background: #f1f3f4; 
            color: #333; 
        }}
        .btn-copy:hover {{ background: #e9ecef; }}
        .footer {{ 
            background: #333; 
            color: white; 
            text-align: center; 
            padding: 20px; 
            margin-top: 60px; 
        }}
        @media (max-width: 768px) {{
            .header h1 {{ font-size: 2rem; }}
            .stats {{ gap: 20px; }}
            .articles-grid {{ grid-template-columns: 1fr; }}
            .article-card {{ flex-direction: column; }}
            .article-thumbnail {{ width: 100%; height: 180px; }}
        }}
    </style>
</head>
<body>
    <header class="header">
        <h1>ğŸ¤– AI ì¬ì‘ì„± ê¸€ ëª©ë¡</h1>
        <p>í‹°ìŠ¤í† ë¦¬ ì›ë³¸ ê¸€ì„ AIë¡œ ì¬ì°½ì‘í•œ ê³ í’ˆì§ˆ ì½˜í…ì¸  ëª¨ìŒ</p>
    </header>
    
    <div class="container">
        <div class="stats">
            <div class="stat-card">
                <div class="stat-number">{len(articles_info)}</div>
                <div class="stat-label">ì´ ê¸€ ìˆ˜</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">{sum(1 for article in articles_info if article.get('thumbnail'))}</div>
                <div class="stat-label">ì´ë¯¸ì§€ í¬í•¨</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">100%</div>
                <div class="stat-label">AI ì¬ì‘ì„±</div>
            </div>
        </div>
        
        <div class="articles-grid">
            {articles_html}
        </div>
    </div>
    
    <footer class="footer">
        <p>&copy; 2025 AI ì¬ì‘ì„± ê¸€ ëª©ë¡ | Powered by GPT-4.1 & Cloudflare</p>
    </footer>
    
    <script>
        function copyArticleUrl(filename) {{
            const url = 'https://12345-82w.pages.dev/' + filename;
            navigator.clipboard.writeText(url).then(() => {{
                alert('ë§í¬ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!\\n' + url);
            }});
        }}
        
        // í˜ì´ì§€ ë¡œë“œ ì‹œ í†µê³„ ì• ë‹ˆë©”ì´ì…˜
        document.addEventListener('DOMContentLoaded', function() {{
            const numbers = document.querySelectorAll('.stat-number');
            numbers.forEach(number => {{
                const target = number.textContent.replace('%', '');
                if (!isNaN(target)) {{
                    let current = 0;
                    const increment = target / 20;
                    const timer = setInterval(() => {{
                        current += increment;
                        if (current >= target) {{
                            current = target;
                            clearInterval(timer);
                        }}
                        number.textContent = target.includes('%') ? Math.round(current) + '%' : Math.round(current);
                    }}, 50);
                }}
            }});
        }});
    </script>
</body>
</html>"""
    
    return index_html

def generate_additional_content(title, existing_content, api_key):
    """ì¶”ê°€ ì½˜í…ì¸  ìƒì„± (HTML í˜•íƒœ)"""
    if not api_key:
        return "<p>í•´ë‹¹ ë¶„ì•¼ì˜ ì¶”ê°€ì ì¸ ë™í–¥ê³¼ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤.</p>"
    
    try:
        if HAS_OPENAI:
            client = OpenAI(api_key=api_key)
            
            prompt = f"""
ê¸°ì‚¬ ì œëª©: {title}
ê¸°ì‚¬ ë‚´ìš© ìš”ì•½: {existing_content[:500]}...

ìœ„ ê¸°ì‚¬ì™€ ê´€ë ¨ëœ ì¶”ê°€ HTML ì½˜í…ì¸ ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. HTML íƒœê·¸ë¡œ ì‘ì„± (<p>, <strong>, <h2> ë“±)
2. 35-60ëŒ€ ë…ìì¸µì—ê²Œ ìœ ìµí•œ ë‚´ìš©
3. 2-3ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±
4. **í•µì‹¬ ì •ë³´ëŠ” <strong> íƒœê·¸ë¡œ** ê°•ì¡°

HTML í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
"""
            
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ HTML ì½˜í…ì¸  ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì‚¬ì™€ ì—°ê´€ì„± ìˆëŠ” HTML ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
                
    except Exception as e:
        print(f"âš ï¸ ì¶”ê°€ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
        return "<p>í•´ë‹¹ ë¶„ì•¼ì˜ <strong>ìµœì‹  ë™í–¥ê³¼ ë¶„ì„</strong>ì„ ì œê³µí•©ë‹ˆë‹¤.</p>"

def convert_markdown_to_html(markdown_content):
    """ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜ (í‹°ìŠ¤í† ë¦¬ìš©)"""
    html_content = markdown_content
    
    # H5 í—¤ë”©ì„ HTMLë¡œ ë³€í™˜
    html_content = re.sub(r'^##### (.+)$', r'<h5>\1</h5>', html_content, flags=re.MULTILINE)
    
    # H2 í—¤ë”©ì„ HTMLë¡œ ë³€í™˜
    html_content = re.sub(r'^## (.+)$', r'<h2>\1</h2>', html_content, flags=re.MULTILINE)
    
    # ë³¼ë“œ í…ìŠ¤íŠ¸ë¥¼ HTMLë¡œ ë³€í™˜
    html_content = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', html_content)
    
    # ì´ë¯¸ì§€ë¥¼ HTMLë¡œ ë³€í™˜
    html_content = re.sub(r'!\[([^\]]*)\]\(([^\)]+)\)', r'<img src="\2" alt="\1" style="max-width:100%;height:auto;">', html_content)
    
    # ë¬¸ë‹¨ ë¶„ë¦¬ë¥¼ ìœ„í•´ ë¹ˆ ì¤„ì„ <p> íƒœê·¸ë¡œ ê°ì‹¸ê¸°
    paragraphs = html_content.split('\n\n')
    html_paragraphs = []
    
    for paragraph in paragraphs:
        paragraph = paragraph.strip()
        if paragraph:
            # HTML íƒœê·¸ê°€ ì—†ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” p íƒœê·¸ë¡œ ê°ì‹¸ê¸°
            if not re.match(r'^<[^>]+>', paragraph):
                paragraph = f'<p>{paragraph}</p>'
            html_paragraphs.append(paragraph)
    
    return '\n\n'.join(html_paragraphs)

# ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - HTML ì§ì ‘ ìƒì„±ìœ¼ë¡œ ëŒ€ì²´ë¨


def main():
    """ë©”ì¸ í•¨ìˆ˜ - í‹°ìŠ¤í† ë¦¬ ì‚¬ì´íŠ¸ë§µ ì²˜ë¦¬"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
    sitemap_url = get_env_var('SITEMAP_URL', 'https://difks2004.tistory.com/sitemap.xml')
    ai_api_key = get_env_var('OPENAI_API_KEY')
    
    # Cloudflare Images ì„¤ì • (í•˜ë“œì½”ë”©)
    cloudflare_account_id = "5778a7b9867a82c2c6ad6d104d5ebb6d"
    cloudflare_api_token = get_env_var('CLOUDFLARE_API_TOKEN')  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
    cloudflare_account_hash = "BhPWbivJAhTvor9c-8lV2w"
    
    # ë””ë²„ê¹…: API í‚¤ ìƒíƒœ í™•ì¸
    print(f"[DEBUG] API Key Debug Info:")
    print(f"   - API key exists: {'Yes' if ai_api_key else 'No'}")
    print(f"   - API key length: {len(ai_api_key) if ai_api_key else 0}")
    print(f"   - API key starts with 'sk-': {'Yes' if ai_api_key and ai_api_key.startswith('sk-') else 'No'}")
    print(f"   - HAS_OPENAI: {HAS_OPENAI}")
    if ai_api_key:
        print(f"   - API key preview: {ai_api_key[:10]}...")
    
    # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸
    if HAS_OPENAI:
        try:
            test_client = OpenAI(api_key=ai_api_key)
            print(f"   - OpenAI client creation: OK")
        except Exception as e:
            print(f"   - OpenAI client creation: ERROR {e}")
    else:
        print(f"   - OpenAI library not available")
    
    # ì²˜ë¦¬ëœ ê¸°ì‚¬ DB ì´ˆê¸°í™”
    init_processed_db()
    
    if len(sys.argv) > 1:
        sitemap_url = sys.argv[1]
    
    print(f"ğŸš€ í‹°ìŠ¤í† ë¦¬ ê¸€ AI ì¬ì‘ì„± ë° HTML ìƒì„± ì‹œì‘...")
    print(f"ğŸ“¥ ì›ë³¸ ì‚¬ì´íŠ¸ë§µ: {sitemap_url}")
    print(f"ğŸ¤– AI ì¬ì‘ì„±: {'âœ…' if ai_api_key else 'âŒ'}")
    print(f"â˜ï¸ Cloudflare Images: {'âœ…' if cloudflare_api_token else 'âŒ'}")
    print(f"ğŸ“„ HTML íŒŒì¼ ì €ì¥: output/ í´ë”")
    
    # ì‚¬ì´íŠ¸ë§µ ë‹¤ìš´ë¡œë“œ
    try:
        response = requests.get(sitemap_url)
        response.raise_for_status()
        sitemap_content = response.text
        print(f"âœ… Downloaded sitemap: {len(sitemap_content):,} bytes")
    except Exception as e:
        print(f"âŒ Error downloading sitemap: {e}")
        sys.exit(1)
    
    # URL ì¶”ì¶œ (í‹°ìŠ¤í† ë¦¬ ì‚¬ì´íŠ¸ë§µì—ì„œ entryë§Œ)
    entry_urls = []
    try:
        root = ET.fromstring(sitemap_content)
        # ì‚¬ì´íŠ¸ë§µ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
        namespaces = {
            '': 'http://www.sitemaps.org/schemas/sitemap/0.9'
        }
        
        for url_elem in root.findall('.//url', namespaces):
            loc_elem = url_elem.find('loc', namespaces)
            if loc_elem is not None:
                url = loc_elem.text
                if url and '/entry/' in url:
                    entry_urls.append(url)
                    
    except Exception as e:
        print(f"âš ï¸ Error parsing XML: {e}")
        # ëŒ€ì•ˆ íŒŒì‹±
        lines = sitemap_content.split('\n')
        for line in lines:
            if '<loc>' in line and '</loc>' in line:
                start = line.find('<loc>') + 5
                end = line.find('</loc>')
                if start > 4 and end > start:
                    url = line[start:end]
                    if '/entry/' in url:
                        entry_urls.append(url)
    
    # URL ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„ (í…ŒìŠ¤íŠ¸ìš© 1ê°œë§Œ ì²˜ë¦¬)
    urls = entry_urls[:1]  # ì²« ë²ˆì§¸ ê¸€ë§Œ ì²˜ë¦¬
    import random
    if len(entry_urls) > 1:
        random.shuffle(entry_urls)
        urls = entry_urls[:1]  # ëœë¤í•˜ê²Œ ì„ì€ í›„ 1ê°œë§Œ ì„ íƒ
    
    # í‹°ìŠ¤í† ë¦¬ ê¸€ì„ HTMLë¡œ ë³€í™˜ ê³„íš
    total_articles = len(urls)
    
    print(f"ğŸ“Š í‹°ìŠ¤í† ë¦¬ ê¸€ AI ì¬ì‘ì„± ë° í¬ìŠ¤íŒ… ê³„íš:")
    print(f"   ğŸ“ í‹°ìŠ¤í† ë¦¬ ì‚¬ì´íŠ¸ë§µì—ì„œ ìˆ˜ì§‘: {len(entry_urls)}ê°œ")
    print(f"   ğŸ¯ ì´ ì²˜ë¦¬ ëŒ€ìƒ: {len(urls)}ê°œ")
    print(f"   ğŸ¤– AI ì¬ì‘ì„± ì˜ˆì •: {total_articles}ê°œ (100%)")
    
    # ğŸ”¥ í‹°ìŠ¤í† ë¦¬ ê¸€ â†’ AI ì¬ì‘ì„± â†’ ë‹¤ë¥¸ í‹°ìŠ¤í† ë¦¬ì— í¬ìŠ¤íŒ…
    print(f"ğŸ” AI ì¬ì‘ì„± í›„ ìë™ í¬ìŠ¤íŒ… ì‹œì‘ - {len(urls)}ê°œ URL ì²˜ë¦¬")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = 'output'
    os.makedirs(output_dir, exist_ok=True)
    
    # ğŸ“Š ì²˜ë¦¬ ì „ ì¤‘ë³µ ì²´í¬ í†µê³„
    duplicate_count = 0
    db_path = 'processed_articles.db'
    
    if os.path.exists(db_path):
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        for url in urls:
            cursor.execute('SELECT COUNT(*) FROM processed_articles WHERE url = ?', (url,))
            if cursor.fetchone()[0] > 0:
                duplicate_count += 1
        
        conn.close()
    
    print(f"ğŸ“ˆ Processing Statistics:")
    print(f"   ğŸ”— Total URLs: {len(urls)}")
    print(f"   ğŸ”„ Already processed: {duplicate_count}")
    print(f"   ğŸ†• New to process: {len(urls) - duplicate_count}")
    
    # ì²˜ë¦¬ í†µê³„
    processed = 0
    skipped = 0
    failed = 0
    
    # ìƒì„±ëœ ê¸€ ì •ë³´ ì €ì¥ (ì¸ë±ìŠ¤ í˜ì´ì§€ìš©)
    generated_articles = []
    
    # ëª¨ë“  ê¸€ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ í•´ì œ)
    # urls = urls[:1]  # í…ŒìŠ¤íŠ¸ ì™„ë£Œ
    
    for i, url in enumerate(urls):
        print(f"\nğŸ“„ [{i+1}/{len(urls)}] Processing: {url.split('/')[-2:]}")
        print(f"ğŸ”— Full URL: {url}")  # ì „ì²´ URL í™•ì¸ìš©
        
        # ğŸ›¡ï¸ URL ê¸°ë°˜ ì‚¬ì „ ì¤‘ë³µ ì²´í¬ (ë¹ ë¥¸ ìŠ¤í‚µ)
        if os.path.exists(db_path):
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM processed_articles WHERE url = ?', (url,))
            is_processed = cursor.fetchone()[0] > 0
            conn.close()
            
            if is_processed:
                print(f"â­ï¸ Skipping already processed URL: {url}")
                skipped += 1
                continue
        
        print(f"ğŸ•·ï¸ Crawling content from URL...")
        article_data = extract_content_from_url(url)
        
        if article_data:
            print(f"âœ… Crawled title: {article_data.get('title', 'No title')}")
            print(f"ğŸ“ Content length: {len(article_data.get('content', ''))} characters")
        else:
            print(f"âŒ Failed to crawl content")
        
        if article_data:
            # AIë¡œ ê¸€ ì¬ì‘ì„±
            try:
                if ai_api_key:
                    print(f"ğŸ¤– Starting AI rewrite...")
                    print(f"ğŸ“° Original title: {article_data['title']}")
                    print(f"ğŸ“„ Original content preview: {article_data['content'][:200]}...")
                    
                    # ì œëª© ì¬ì‘ì„±
                    new_title = rewrite_title_with_ai(
                        article_data['title'],
                        article_data['content'],
                        ai_api_key
                    )
                    
                    if new_title and new_title != article_data['title']:
                        # ë³¸ë¬¸ ì¬ì‘ì„±
                        rewritten_content = rewrite_with_ai(
                            article_data['content'], 
                            new_title,
                            ai_api_key
                        )
                        
                        if rewritten_content and rewritten_content != article_data['content']:
                            # ì¬ì‘ì„±ëœ ê¸€ ë°ì´í„° ì¤€ë¹„
                            rewritten_article = {
                                'title': new_title,
                                'content': rewritten_content,
                                'tags': article_data.get('tags', []) + ['AIì¬ì‘ì„±', 'ìë™í¬ìŠ¤íŒ…'],
                                'url': url
                            }
                            
                            # Cloudflareì— ì´ë¯¸ì§€ ì—…ë¡œë“œ
                            cloudflare_images = []
                            if cloudflare_api_token and article_data.get('images'):
                                print(f"ğŸ“¸ Uploading {len(article_data['images'])} images to Cloudflare...")
                                for img_url in article_data['images'][:5]:  # ìµœëŒ€ 5ê°œ
                                    cf_url = upload_to_cloudflare_images(img_url, cloudflare_api_token, cloudflare_account_id)
                                    if cf_url:
                                        cloudflare_images.append(cf_url)
                                    time.sleep(1)  # API ì œí•œ ê³ ë ¤
                            
                            # HTML íŒŒì¼ ìƒì„±
                            html_content = generate_article_html(rewritten_article, cloudflare_images)
                            
                            # HTML íŒŒì¼ ì €ì¥
                            output_dir = 'output'
                            os.makedirs(output_dir, exist_ok=True)
                            
                            # íŒŒì¼ëª… ìƒì„± (ì•ˆì „í•œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜)
                            safe_filename = re.sub(r'[^\w\s-]', '', new_title)
                            safe_filename = re.sub(r'[-\s]+', '-', safe_filename)
                            safe_filename = safe_filename.strip('-')[:50]  # ê¸¸ì´ ì œí•œ
                            
                            html_filepath = os.path.join(output_dir, f"{safe_filename}.html")
                            
                            # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€
                            counter = 1
                            while os.path.exists(html_filepath):
                                html_filepath = os.path.join(output_dir, f"{safe_filename}-{counter}.html")
                                counter += 1
                            
                            try:
                                with open(html_filepath, 'w', encoding='utf-8') as f:
                                    f.write(html_content)
                                print(f"âœ… HTML íŒŒì¼ ìƒì„±: {html_filepath}")
                                processed += 1
                                
                                # ì¸ë±ìŠ¤ í˜ì´ì§€ìš© ì •ë³´ ì €ì¥
                                generated_articles.append({
                                    'title': new_title,
                                    'filename': os.path.basename(html_filepath),
                                    'tags': rewritten_article['tags'],
                                    'thumbnail': cloudflare_images[0] if cloudflare_images else '',
                                    'url': url
                                })
                                
                            except Exception as e:
                                print(f"âŒ HTML íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
                                failed += 1
                            
                            # ì›ë˜ í‹°ìŠ¤í† ë¦¬ í¬ìŠ¤íŒ… ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬)
                            """
                            # ë°”ë¡œ í‹°ìŠ¤í† ë¦¬ì— í¬ìŠ¤íŒ…
                            try:
                                from tistory_selenium_poster import TistorySeleniumPoster
                                poster = TistorySeleniumPoster()
                                
                                if poster.setup_driver(headless=True):
                                    if poster.login_tistory():
                                        if poster.write_post(
                                            title=rewritten_article['title'],
                                            content=rewritten_article['content'],
                                            tags=rewritten_article['tags'],
                                            is_draft=True
                                        ):
                                            processed += 1
                                            print(f"âœ… í‹°ìŠ¤í† ë¦¬ í¬ìŠ¤íŒ… ì„±ê³µ: {new_title[:30]}...")
                                        else:
                                            failed += 1
                                            print(f"âŒ í‹°ìŠ¤í† ë¦¬ í¬ìŠ¤íŒ… ì‹¤íŒ¨: {new_title[:30]}...")
                                    else:
                                        failed += 1
                                        print(f"âŒ í‹°ìŠ¤í† ë¦¬ ë¡œê·¸ì¸ ì‹¤íŒ¨")
                                    
                                    if poster.driver:
                                        poster.driver.quit()
                                else:
                                    failed += 1
                                    print(f"âŒ ë¸Œë¼ìš°ì € ì„¤ì • ì‹¤íŒ¨")
                                    
                            except Exception as e:
                                failed += 1
                                print(f"âŒ í¬ìŠ¤íŒ… ì˜¤ë¥˜: {e}")
                            """
                        else:
                            failed += 1
                            print(f"âŒ AI ë³¸ë¬¸ ì¬ì‘ì„± ì‹¤íŒ¨")
                    else:
                        failed += 1
                        print(f"âŒ AI ì œëª© ì¬ì‘ì„± ì‹¤íŒ¨")
                else:
                    failed += 1
                    print(f"âŒ AI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                    
            except Exception as e:
                failed += 1
                print(f"âŒ ê¸€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                
            print(f"ğŸ¯ Progress: {processed} processed, {skipped} skipped, {failed} failed")
        else:
            failed += 1
            print(f"âŒ Failed to extract content from: {url}")
        
        # API ì œí•œ ê³ ë ¤ ëŒ€ê¸° (ì²˜ë¦¬ëŸ‰ì— ë”°ë¼ ì¡°ì •)
        if processed > 0 and processed % 10 == 0:
            print(f"â¸ï¸ Processed {processed} articles, taking a short break...")
            time.sleep(5)  # 10ê°œë§ˆë‹¤ 5ì´ˆ ëŒ€ê¸°
        else:
            time.sleep(random.uniform(1, 2))
    
    print(f"\nğŸ“Š Final Processing Summary:")
    print(f"âœ… Successfully Processed: {processed}")
    print(f"â­ï¸ Skipped (Duplicates): {skipped}")
    print(f"âŒ Failed: {failed}")
    print(f"ğŸ“ˆ Total URLs Checked: {len(urls)}")
    
    if processed > 0:
        print(f"ğŸ‰ Successfully created {processed} new AI-rewritten articles!")
        print(f"ğŸ’¾ Database updated with {processed + skipped} processed URLs")
    else:
        print("â„¹ï¸ No new articles were created - all URLs already processed or failed")
    
    # ğŸ“Š DB ìƒíƒœ í™•ì¸
    try:
        db_path = 'processed_articles.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM processed_articles')
        total_processed = cursor.fetchone()[0]
        conn.close()
        print(f"ğŸ—„ï¸ Total articles in database: {total_processed}")
    except Exception as e:
        print(f"âš ï¸ Could not check database: {e}")
    
    # articles.json íŒŒì¼ ìƒì„± (JavaScriptìš©)
    if generated_articles:
        try:
            articles_data = {
                "meta": {
                    "total_articles": len(generated_articles),
                    "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "with_images": sum(1 for article in generated_articles if article.get('thumbnail')),
                    "ai_rewritten": "100%"
                },
                "articles": generated_articles
            }
            
            json_filepath = os.path.join(output_dir, 'articles.json')
            with open(json_filepath, 'w', encoding='utf-8') as f:
                json.dump(articles_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ“„ articles.json ìƒì„±: {json_filepath}")
            print(f"ğŸ”— JavaScriptì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„° íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì¸ë±ìŠ¤ HTML ìƒì„±
            index_html = generate_index_html(generated_articles)
            index_filepath = os.path.join(output_dir, 'index.html')
            with open(index_filepath, 'w', encoding='utf-8') as f:
                f.write(index_html)
            print(f"ğŸ“„ index.html ìƒì„±: {index_filepath}")
            
        except Exception as e:
            print(f"âŒ articles.json ìƒì„± ì‹¤íŒ¨: {e}")

    print(f"\nğŸ‰ HTML íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {processed}ê°œ")  
    print(f"âŒ ì‹¤íŒ¨: {failed}ê°œ")
    print(f"â­ï¸ ê±´ë„ˆëœ€: {skipped}ê°œ")
    print(f"ğŸ“ ì¶œë ¥ í´ë”: output/")
    print(f"ğŸ“„ ë°ì´í„° íŒŒì¼: output/articles.json")
    
    print(f"ğŸ”š ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main() 